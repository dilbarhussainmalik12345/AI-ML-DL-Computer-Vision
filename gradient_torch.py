# -*- coding: utf-8 -*-
"""Gradient_torch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x-PRBPRVJk9I6kyvZAbJzodjrjup_blo
"""

import torch

# f = 2*x
X = torch.tensor([1,2,3,4], dtype = torch.float32)
Y = torch.tensor([2,4,6,8], dtype = torch.float32)

w = torch.tensor(0.0, dtype = torch.float32, requires_grad = True)


#Model prediction
def forward(x):
  return w * x

#Loss (Mean Square area)
def loss(y, ypred):
  return ((ypred - y)**2).mean()

  print(f'Prediction Before Training: f(5)= {forward(5):.3f}')


  #Training
learning_rate = 0.01
n_iters = 1000
for epoch in range(n_iters):
  #prediction  = forward pass
  ypred = forward(X)

  #loss
  l = loss(Y, ypred)

  #gradients = backward pass
l.backward()

  #Update the weights
with torch.no_grad():
 w -= learning_rate * w.grad

#Zero gradients
w.grad.zero_()

if epoch % 10 == 0:
  print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')

print(f'Prediction After Training: f(5)= {forward(5):.3f}')

#training
learning_rate = 0.01
n_iters = 20

